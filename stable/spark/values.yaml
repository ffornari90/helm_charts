# Default values for Spark.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.



#ClusterRoleBinding parameters
clusterRoleBinding:
    name: default-pyspark
    namespace: default
    subjects:
        kind: User
        name: system:serviceaccount:default:default
        apiGroup: rbac.authorization.k8s.io
    roleRef:
        kind: ClusterRole
        name: edit
        apiGroup: rbac.authorization.k8s.io

# ExternalIps to be used for service exposition
externalIp:
    enabled: true
    ips: 192.168.65.3 

# Spark master deployment and service configuration values
master:
    name: master
    namespace: default
    image: ttedesch/spark-py
    imageTag: base_k8s_2.4.4_client_4.4.2
    #image: ttedesch/spark-py 
    #imageTag: base_k8s_2.4.4 
    #image: cloudpg/spark-py
    #imageTag: dodas-2.4.3-bigdl
    replicas: 1
    component: spark-master
    cpu: 100m
    memory: 1024Mi
    servicePort: 7077
    containerPort: 7077
    # Set Master JVM memory. Default 1g
    # DaemonMemory: 1g
    serviceType: NodePort
    jupyter:
        nodePort: 30888
        token: testme
        port: 8888
        image: ttedesch/pyspark-notebook
        tag: customized_3.6
        #image: ttedesch/all-spark-notebook  
        #tag: customized_v5_3.6 
        #image: ttedesch/pyspark_jupyter
        #tag: latest
        #image: cloudpg/spark-notebook
        #tag: k8s-py3.6


# WebUi service configuration values
webUi:
  name: webui
  namespace: default
  servicePort: 8080
  containerPort: 8080
  nodePort: 30808
  serviceType: NodePort

# Where to store jupyter data
hostPath: 
    path: /tmp
